{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5.1**\n",
    "\n",
    "Consider the diagrams on the right in Figure 5.1. Why does the estimated value function jump up for the last two rows in the rear ? Why does it drop off for the whole last row on the left? Why are the frontmost values higher in the upper diagrams than in the lower?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value jumps up because with a sum of 20 or 21, the player's chances of winning are high and he should obviously not hit. <br>\n",
    "They drop off for the row on the left (when the dealer has an Ace) because the Ace is a good card. It's like a safety layer when you hit and the sum exceeds 21 you can retry. <br>\n",
    "The frontmost values are higher in the upper diagrams than in the lower because of the same reason, having a usable ace is a safety layer and is better than not having one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5.2**\n",
    "\n",
    "Suppose every-visit MC was used instead of first-visit MC on the blackjack task. Would you expect the results to be very different? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we defined the states being the sum of the agent's cards, and one of the dealer's card make it that it's very rare to encounter the same state twice in one episode. For instance, the sum of the agent's cards can only increase throughout the game. The very rare case only happens when there is a usable ace (example: the agent has an ace and a 2, adding up to 13. He hits and gets a face card, adding +10 and ends at 23. He makes his ace count as 1, so he's back at 13.) <br>\n",
    "So in Blackjack, first-visit MC and every-visit MC are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5.3**\n",
    "\n",
    "What is the backup diagram for Monte Carlo estimation of $q_\\pi$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5.4**\n",
    "\n",
    "The pseudocode for Monte-Carlo ES is inefficient because for all state-action pairs, it maintains a list of all returns and repeatedly calculates their mean. It would be more efficient to use techniques similar to those in section 2.4 to maintain just the mean and a count (for each state-action pair) and update them incrementally. Describe how the pseudocode would be altered to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the initialization :\n",
    "- Remove $Returns(s,a)$\n",
    "- Set $Q(s,a) \\leftarrow 0$ for all s,a\n",
    "- Introduce $N(s,a) \\leftarrow 0$ for all s,a <br>\n",
    "  \n",
    "In the loop :\n",
    "- $N(S_t,A_t) \\leftarrow N(S_t,A_t) + 1$\n",
    "- $Q(S_t,A_t) \\leftarrow Q(S_t,A_t) + \\frac{1}{N(S_t,A_t)} [G - Q(S_t,A_t)]$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
