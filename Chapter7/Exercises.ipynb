{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.1**\n",
    "\n",
    "In Chapter 6 we noted that the Monte Carlo error can be written as the sum of TD errors (6.6) if the value estimates don't change from step to step. Show that the n-step error used in (7.2) can also be written as a sum of TD errors (again if the vavlue estimates don't cahnge) generalizing the earlier result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Reminder of equation (7.2)\n",
    "\n",
    "\\begin{aligned}\n",
    "    V_{t+n}(S_t) = V_{t+n-1}(S_t) + \\alpha [ G_{t:t+n} - V_{t+n-1}(S_t) ]\n",
    "\\end{aligned}\n",
    "\n",
    "**ANSWER**\n",
    "\n",
    "\\begin{aligned}\n",
    "    G_t - V(S_t) &= R_{t+1} + \\gamma R_{t+2} + \\cdots + \\gamma^{n-1} R_{t+n} + \\cdots \\gamma^{T-t-1} R_T - V(S_t) + V(S_{t+n}) - V(S_{t+n}) \\\\\n",
    "    &= \\delta_t + \\gamma^n (G_{t+n} - V(S_{t+n})) \\\\\n",
    "    &= \\delta_t + \\gamma^n \\delta_{t+n} + \\gamma^2n (G_{t+2n} - V(S_{t+2n})) \\\\\n",
    "    &= \\cdots \\\\\n",
    "    &= \\sum_{k=0}^{\\bar{k}} \\gamma^{kn} \\delta_{t+kn}\n",
    "\\end{aligned}\n",
    "\n",
    "where $\\bar{k} = floor({\\frac{T-t-1}{n}})$ and $\\delta_t = G_{t:t+n} - V(S_t)$. (For $t+n > T$, $G_{t:t+n}$ is simply $G_t$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if $T=10, t=5, n=2, \\bar{k}=floor(\\frac{4}{2})=2$, then:\n",
    "\n",
    "\\begin{aligned}\n",
    "    G_5 - V(S_5) = \\delta_5 + \\gamma^2 \\delta_7 + \\gamma^4 \\delta_9\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.2 (programming)**\n",
    "\n",
    "With an n-step method, the value estimates do change from step to step, so an algorithm that used the sum of TD errors (see previous exercise) in place of the error in (7.2) would actually be a shlightly different algorithm. Would it be a better algorithm or a worse one? Devise and program a small experiment to answer this question empirically.\n",
    "\n",
    "**ANSWER**\n",
    "\n",
    "I'm not sure I understand the question well. Using the sum of TD errors seems like a big change, not a slight change because we have to wait until the end of the episode to update our value estimates. I think it would probably be worse because we assumed $V$ doesn't change to write our MC error as a sum of TD errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.3**\n",
    "\n",
    "Why do you think a larger random walk task (19 states instead of 5) was used in the examples of this chapter? Would a smaller walk have shifted the avantage to a different value of n? How about the change in left-side outcome from 0 to -1 made in the larger walk? Do you think that made any difference in the best value of n?\n",
    "\n",
    "**ANSWER**\n",
    "\n",
    "- First, it allows us to see the results for larger n\n",
    "- Second, it reduces the variance in value estimates. Consider the following setting $\\alpha=\\frac{1}{2}, n=5, V(S_t)=0.5$ with 5 non-terminal states. Imagine that in the first episode, the agent finds itself at state A, then the agent only moves right 5 times in a row. It could happen with probability $(\\frac{1}{2})^5 = \\frac{1}{32} \\approx 3\\% $. It would then update all the states A,B,C,D,E values to 0.75 exactly. (Because $V(S) \\leftarrow 0.5 + \\frac{1}{2} [1 - 0.5] = 0.75$ for all states). This is obviously not good for states A,B,C, whose real values are $\\frac{1}{6}, \\frac{2}{6}, \\frac{3}{6}$. <br> \n",
    "Now with mores states, say n states, the probability that agent moves only right n times in a row starting from state A is more and more unlikely as n grows. With n=19, the probability is only $\\frac{1}{2^{19}}$. High variance would not help us determining which n is better.\n",
    "\n",
    "As for changing the left-side outcome from 0 to -1, I don't think it changes anything as long as the initial state values is set to 0. Consider the following setting $\\alpha=\\frac{1}{2}, n=2, V(S_t)=0$ with 5 non-terminal states:\n",
    "\n",
    "Imagine that the agent goes left only, for a reward of +1 on the right side outcome only and 0.5 as initial value estimates, it would therefore do the following updates:\n",
    "- $V(B) \\leftarrow 0.5 + \\frac{1}{2} [0 - 0.5] = 0.25$. **error**: $|0.25 - \\frac{2}{6}| = \\frac{1}{12}$\n",
    "- $V(A) \\leftarrow 0.5 + \\frac{1}{2} [0 - 0.5] = 0.25$. **error**: $|0.25 - \\frac{1}{6}| = \\frac{1}{12}$\n",
    "- 0.25 is the middle between the reward on left-side and the initial value, that is 0 and 0.5 \n",
    "\n",
    "For a reward of +1 on the right side outcome, -1 on the left side, and 0 as initial value estimates:\n",
    "- $V(B) \\leftarrow 0 + \\frac{1}{2} [-1 - 0] = -0.5$. **error**: $|-0.5 - (-\\frac{2}{3})| = \\frac{1}{6}$\n",
    "- $V(A) \\leftarrow 0 + \\frac{1}{2} [-1 - 0] = -0.5$ **error**: $|-0.5 - (-\\frac{1}{3})| = \\frac{1}{6}$\n",
    "- -0.5 is the middle between the reward on left-side and the initial value, that is -1 and 0\n",
    "\n",
    "Except the change in the scale of the values and errors (and potentially the need to change the scale of $\\alpha$), it doesn't fundamentally change the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.4**\n",
    "\n",
    "Prove that the n-step return of Sarsa (7.4) can be written exactly in terms of a novel TD error, as:\n",
    "\n",
    "\\begin{align}\n",
    "    G_{t:t+n} = Q_{t-1}(S_t,A_t) + \\sum_{k=t}^{min(t+n,T)-1} \\gamma^{k-t} [ R_{k+1} + \\gamma Q_k(S_{k+1},A_{k+1}) - Q_{k-1}(S_k,A_k) ]\n",
    "\\end{align}\n",
    "\n",
    "**ANSWER**\n",
    "\n",
    "We can simply notice that in the sum, $\\gamma Q_k(S_{k+1},A_{k+1})$ cancels $- Q_{k-1}(S_k,A_k)$ for the next k. It is a the sum of a telescoping series. The result is simply the first $- Q_{k-1}(S_k,A_k)$ and the last $\\gamma Q_k(S_{k+1},A_{k+1})$ (ignoring $R_{k+1}$):\n",
    "\n",
    "\\begin{aligned}\n",
    "    & \\sum_{k=t}^{min(t+n,T)-1} \\gamma^{k-t} [ R_{k+1} + \\gamma Q_k(S_{k+1},A_{k+1}) - Q_{k-1}(S_k,A_k) ] \\\\\n",
    "    &= \n",
    "    \\begin{cases}\n",
    "        R_{t+1} - Q_{t-1}(S_t,A_t) + \\gamma^{n-1} R_{t+n} + \\gamma^n Q_{t+n-1}(S_{t+n},A_{t+n}) & \\text{if } t+n<T \\\\\n",
    "        R_{t+1} - Q_{t-1}(S_t,A_t) + \\gamma^{T-1} R_{T} & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{aligned}\n",
    "\n",
    "Therefore\n",
    "\\begin{aligned}\n",
    "    & Q_{t-1}(S_t,A_t) + \\sum_{k=t}^{min(t+n,T)-1} \\gamma^{k-t} [ R_{k+1} + \\gamma Q_k(S_{k+1},A_{k+1}) - Q_{k-1}(S_k,A_k) ] \\\\\n",
    "    &= \n",
    "    \\begin{cases}\n",
    "        R_{t+1} + \\gamma^{n-1} R_{t+n} + \\gamma^n Q_{t+n-1}(S_{t+n},A_{t+n}) & \\text{if } t+n<T \\\\\n",
    "        R_{t+1} + \\gamma^{T-1} R_{T} & \\text{otherwise}\n",
    "    \\end{cases} \\\\\n",
    "    &= G_{t:t+n}\n",
    "\\end{aligned}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
